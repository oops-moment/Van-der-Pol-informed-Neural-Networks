{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\anshu\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN:\n",
    "\n",
    "    def __init__(self, mu, training):\n",
    "        self.t_diff = 1  # Daily data\n",
    "        self.gradient_t = (training.diff() / self.t_diff).iloc[1:]  # dx/dt\n",
    "        self.gradient_tt = (self.gradient_t.diff() /\n",
    "                            self.t_diff).iloc[1:]  # d2x/dt2\n",
    "        self.gradient_t = self.gradient_t.reset_index(drop=True)\n",
    "        self.gradient_tt = self.gradient_tt.reset_index(drop=True)\n",
    "        self.mu = mu\n",
    "\n",
    "    def load_data(self, filename, coloumn_number):\n",
    "        self.data = pd.read_csv(filename)\n",
    "        self.training_set = self.data.iloc[:, coloumn_number]\n",
    "        self.test = self.training_set.tail(10)\n",
    "        self.training_set = self.training_set.iloc[:-10]\n",
    "        self.training_set = self.training_set.reset_index(drop=True)\n",
    "        self.df = pd.concat((self.training_set, self.gradient_t), axis=1)\n",
    "        self.gradient_tt.columns = [\"grad_tt\"]\n",
    "        self.pd.concat((self.df, self.gradient_tt), axis=1)\n",
    "        self.df.columns = [\"y_t\", \"grad_t\", \"grad_tt\"]\n",
    "\n",
    "    # def plot_inital(self):\n",
    "    #     self.iloc[:, 0].plot()\n",
    "    #     self.L = self.df.iloc[:, 2] - self.mu * (self.df.iloc[:, 1] - (self.df.iloc[:, 0]**2 * self.df.iloc[:, 1]) - (1/self.mu) * self.df.iloc[:, 0])\n",
    "    #     self.L.plot()\n",
    "\n",
    "    def convert(self, offset=30, in_val=35, out_val=10):\n",
    "        self.offset = offset\n",
    "        self.in_val = in_val\n",
    "        self.out_val = out_val\n",
    "\n",
    "        self.data = Supervised(self.df.values, in_val, out_val)\n",
    "        cols_to_drop = [\n",
    "            f\"var{i}(t-{j})\" for j in range(in_val, 1, -1)\n",
    "            for i in range(2, 4)\n",
    "        ]\n",
    "        self.data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "        self.train = np.array(self.data[0:len(self.data) - 1])\n",
    "        self.forecast = np.array(self.data.tail(1))\n",
    "\n",
    "        self.trainy = self.train[:, -offset:]\n",
    "        self.trainX = self.train[:, :-offset]\n",
    "\n",
    "        self.forecasty = self.forecast[:, -offset:]\n",
    "        self.forecastX = self.forecast[:, :-offset]\n",
    "\n",
    "        self.trainX = self.trainX.reshape(\n",
    "            (self.trainX.shape[0], 1, self.trainX.shape[1]))\n",
    "        self.forecastX = self.forecastX.reshape(\n",
    "            (self.forecastX.shape[0], 1, self.forecastX.shape[1]))\n",
    "\n",
    "    def vpinn_loss_fn(self, y_true, y_pred):\n",
    "        mu = tf.Variable(4, name=\"mu\", trainable=True, dtype=tf.float32)\n",
    "        squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "        #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "        #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "        squared_difference3 = tf.square(y_pred[:, 2] - mu *\n",
    "                                        (y_pred[:, 1] -\n",
    "                                         (y_pred[:, 0]**2 * y_pred[:, 1]) -\n",
    "                                         (1 / mu) * y_pred[:, 0]))\n",
    "        return tf.reduce_mean(\n",
    "            squared_difference,\n",
    "            axis=-1) + 0.2 * tf.reduce_mean(squared_difference3, axis=-1)\n",
    "\n",
    "    def shm_loss_fn(self, y_true, y_pred):\n",
    "        mass = 1.0  # kg\n",
    "        spring_constant = 4.0  # N/m\n",
    "        omega = np.sqrt(spring_constant / mass)\n",
    "\n",
    "        squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "        #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "        #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "        squared_difference3 = tf.square(y_pred[:, 2] +\n",
    "                                        (omega**2) * y_pred[:, 0])\n",
    "        return tf.reduce_mean(\n",
    "            squared_difference,\n",
    "            axis=-1) + 0.2 * tf.reduce_mean(squared_difference3, axis=-1)\n",
    "\n",
    "    def lorenz_loss_fn(self, y_true, y_pred):\n",
    "        mu = tf.Variable(4, name=\"mu\", trainable=True, dtype=tf.float32)\n",
    "        splitr = 0.8\n",
    "        sigma = 10\n",
    "        rho = 28\n",
    "        beta = 8 / 3\n",
    "        squared_difference_x = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "        squared_difference_z = tf.square(y_pred[:, 2] - mu *\n",
    "                                         (y_pred[:, 1] -\n",
    "                                          (y_pred[:, 0]**2) * y_pred[:, 1]))\n",
    "\n",
    "        return tf.reduce_mean(squared_difference_x, axis=-1) + \\\n",
    "                0.2 * tf.reduce_mean(squared_difference_z, axis=-1)\n",
    "\n",
    "    def train_model(self, type):\n",
    "        mu = tf.Variable(4, name=\"mu\", trainable=True, dtype=tf.float32)\n",
    "        splitr = 0.8\n",
    "\n",
    "        self.model = Sequential()\n",
    "        self.model.add(\n",
    "            LSTM(50, input_shape=(self.trainX.shape[1], self.trainX.shape[2])))\n",
    "        self.model.add(Dense(30))\n",
    "        if type == \"VPINN\":\n",
    "            self.model.compile(loss=self.vpinn_loss_fn, optimizer='adam')\n",
    "        elif type == \"SHM\":\n",
    "            self.model.compile(loss=self.shm_loss_fn, optimizer='adam')\n",
    "        elif type == \"LORENZ\":\n",
    "            self.model.compile(loss=self.lorenz_loss_fn, optimizer='adam')\n",
    "        self.history = self.model.fit(\n",
    "            self.trainX[:int(splitr * self.trainX.shape[0])],\n",
    "            self.trainy[:int(splitr * self.trainX.shape[0])],\n",
    "            epochs=100,\n",
    "            batch_size=64,\n",
    "            validation_data=(\n",
    "                self.trainX[int(splitr *\n",
    "                                self.trainX.shape[0]):self.trainX.shape[0]],\n",
    "                self.trainy[int(splitr *\n",
    "                                self.trainX.shape[0]):self.trainX.shape[0]]),\n",
    "            shuffle=False)\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        self.forecast_without_mc = self.forecastX\n",
    "        yhat_without_mc = self.model.predict(\n",
    "            self.forecast_without_mc)  # Step Ahead Prediction\n",
    "        self.forecast_without_mc = self.forecast_without_mc.reshape(\n",
    "            (self.forecast_without_mc.shape[0],\n",
    "             self.forecast_without_mc.shape[2]))  # Historical Input\n",
    "\n",
    "        self.final_forecast = yhat_without_mc[:, 0:self.offset - 1:3]\n",
    "        self.final_forecast[self.final_forecast < 0] = 0\n",
    "        self.true_forecast = self.forecasty[:, 0:self.offset - 1:3]\n",
    "        return mean_absolute_error(self.final_forecast, self.true_forecast)\n",
    "\n",
    "    def plot_forecasts(self, final_forecast, true_forecast):\n",
    "        # Get the length of the prediction\n",
    "        prediction_length = final_forecast.shape[1]\n",
    "\n",
    "        # Create timestamps for x-axis\n",
    "        timestamps = range(prediction_length)\n",
    "\n",
    "        # Plot the forecasts\n",
    "        plt.plot(timestamps,\n",
    "                 final_forecast.flatten(),\n",
    "                 label='Final Forecast',\n",
    "                 color='blue')\n",
    "        plt.plot(timestamps,\n",
    "                 true_forecast.flatten(),\n",
    "                 label='True Forecast',\n",
    "                 color='red')\n",
    "\n",
    "        # Add labels and legend\n",
    "        plt.xlabel('Timestamp')\n",
    "        plt.ylabel('Wind Speed')\n",
    "        plt.legend()\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_set1 = pd.DataFrame(data1).reset_index(drop=True)\n",
    "training_set1 = training_set1.iloc[:,1]\n",
    "PINN_VPN= PINN(4, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
